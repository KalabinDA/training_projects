Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.
Необходимо обучить модель классифицировать комментарии на позитивные и негативные с помощью набора данных с разметкой о токсичности правок.
Построить модель со значением метрики качества F1 не меньше 0.75.

Библиотеки:pandas, numpy, matplotlib, seaborn, sklearn, lightgbm, tqdm, torch, transformers

Для обучения моделей предсказания токсичности текста были получены промаркированные комментарии, всего 159292 записи.
В результате предобработки был удален столбец с индексами, а текст очищен от ненужных символов.
При анализе данных был выявлен сильный дисбаланс целевого признака: токсичные комментарии составляют всего 10% от общего числа.
Для обучения моделей были использованы два способа преобразования слов в понятный для модели векторный вид. Первый это подсчитывающий уникальные слова Tf-Idf, а другой это оценивающий смысловую близость слов эмбеддинг, реализованный в предобученной модели BERT.
Для предсказания токсичности текста в обоих случаях были подобраны гиперпараметры и веса классов для модели логистической регрессии и градиентного бустинга LightGBM
Лучше всего себя показала модель градиентного бустинга, обучавшаяся на эмбеддингах, с порогом классификации равным 0,55.
Итоговая метрика f1 на тестовых данных составила 0,919, что с запасом соответствует требованию.
Модель допускает примерно одинаковое количество ложноположительных и ложноотрицательных ответов, что связано с настройкой на лучшую f1 меру. Для лучшего определения конкретного класса следует провести настройку исходя из других метрик.
