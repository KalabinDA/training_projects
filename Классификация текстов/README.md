# Классификация токсичности текстов
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

## Цели исследования
Необходимо обучить модель классифицировать комментарии на позитивные и негативные на наборе данных с разметкой о токсичности правок и со значением метрики качества *F1* не меньше 0.75. 

## Ход исследования:

1. Загрузка и подготовка данных.
2. Обучение разных моделей. 
3. Выводы.
   
## Библиотеки: 
pandas, matplotlib, seaborn, sklearn, lightgbm, wordcloud, tqdm, torch, transformers, nltk, CUDA


## Вывод:

* Для обучения моделей предсказания токсичности текста были получены промаркированные комментарии, всего 159292 записи.
* В результате предобработки был удален столбец с индексами, а текст очищен от ненужных символов.
* При анализе данных был выявлен сильный дисбаланс целевого признака: токсичные комментарии составляют всего 10% от общего числа.
* Для обучения моделей были использованы два способа преобразования слов в понятный для модели векторный вид. Первый это подсчитывающий уникальные слова Tf-Idf, а другой это оценивающий смысловую близость слов эмбеддинг, реализованный в предобученной модели BERT.
* Для предсказания токсичности текста в обоих случаях были подобраны гиперпараметры и веса классов для модели логистической регрессии и градиентного бустинга LightGBM
* Лучше всего себя показала модель градиентного бустинга, обучавшаяся на эмбеддингах, с порогом классификации равным 0,55.
* Итоговая метрика f1 на тестовых данных составила 0,92, что с запасом соответствует требованию.
* Модель допускает примерно одинаковое количество ложноположительных и ложноотрицательных ответов, что связано с настройкой на лучшую f1 меру. Для лучшего определения конкретного класса следует провести настройку исходя из других метрик.
